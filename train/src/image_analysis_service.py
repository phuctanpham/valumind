# image_analysis_service.py - Enhanced Multi-Pass OCR Strategy
import base64
import json
import os
import logging
from io import BytesIO
from typing import List, Dict, Any
from PIL import Image, ImageEnhance, ImageFilter
from openai import OpenAI
from dotenv import load_dotenv
import cv2
import numpy as np

load_dotenv()

openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
logger = logging.getLogger(__name__)


def preprocess_image_for_ocr(image_bytes: bytes) -> bytes:
    """
    Pre-process áº£nh Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c OCR:
    1. TÄƒng contrast
    2. Sharpen
    3. Denoise
    4. TÄƒng kÃ­ch thÆ°á»›c náº¿u quÃ¡ nhá»
    """
    try:
        img = Image.open(BytesIO(image_bytes))
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Resize náº¿u quÃ¡ nhá»
        width, height = img.size
        if width < 1200:
            scale = 1200 / width
            new_size = (int(width * scale), int(height * scale))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # TÄƒng contrast
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.5)
        
        # TÄƒng sharpness
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(2.0)
        
        # Convert to numpy for OpenCV
        img_array = np.array(img)
        
        # Denoise
        img_array = cv2.fastNlMeansDenoisingColored(img_array, None, 10, 10, 7, 21)
        
        # Convert back to PIL
        img = Image.fromarray(img_array)
        
        # Save to bytes
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=95)
        return buffered.getvalue()
        
    except Exception as e:
        logger.warning(f"Preprocess error: {e}, using original")
        return image_bytes


def encode_image_to_base64(image_file) -> str:
    """Convert image file to base64"""
    image_file.seek(0)
    return base64.b64encode(image_file.read()).decode('utf-8')


def compress_image_if_needed(content: bytes, max_size_mb: float = 20) -> bytes:
    """Compress image náº¿u vÆ°á»£t quÃ¡ giá»›i háº¡n"""
    if len(content) / (1024 * 1024) > max_size_mb:
        img = Image.open(BytesIO(content))
        img.thumbnail((1920, 1440))
        buffered = BytesIO()
        img.save(buffered, format="JPEG", quality=85, optimize=True)
        return buffered.getvalue()
    return content


def convert_bytes_to_base64_for_analysis(content: bytes, preprocess: bool = True) -> str:
    """Convert bytes thÃ nh base64 cho AI analysis"""
    if preprocess:
        content = preprocess_image_for_ocr(content)
    
    img = Image.open(BytesIO(content))
    buffered = BytesIO()
    img.save(buffered, format="JPEG", quality=95)
    return base64.b64encode(buffered.getvalue()).decode()


class ImageToFormAnalyzer:
    """Xá»­ lÃ½ chuyá»ƒn Ä‘á»•i áº£nh báº¥t Ä‘á»™ng sáº£n thÃ nh form/dá»¯ liá»‡u vá»›i multi-pass strategy"""
    
    # Critical fields that must not be missed
    CRITICAL_FIELDS = [
        "usable_area_m2", "bedrooms", "bathrooms", "floors", 
        "direction", "legal_status", "furniture_status", 
        "width_m", "length_m"
    ]
    
    @staticmethod
    def analyze_images_to_form(images_base64: List[str]) -> Dict[str, Any]:
        """
        Multi-pass OCR strategy:
        PASS 1: Comprehensive extraction with focused prompt
        PASS 2: Targeted retry for any missed critical fields
        """
        try:
            # PASS 1: First comprehensive extraction
            logger.info("ğŸ” Starting PASS 1: Comprehensive extraction")
            first_result = ImageToFormAnalyzer._first_pass_extraction(images_base64)
            
            if not first_result['success']:
                return first_result
            
            # Validate critical fields
            missing_fields = ImageToFormAnalyzer._validate_critical_fields(
                first_result['data']
            )
            
            # If all fields present, return immediately
            if not missing_fields:
                logger.info("âœ… All critical fields extracted successfully")
                return first_result
            
            # PASS 2: Targeted retry for missed fields
            logger.warning(f"âš ï¸ Missing fields: {', '.join(missing_fields)}")
            logger.info("ğŸ”„ Starting PASS 2: Targeted retry")
            
            second_result = ImageToFormAnalyzer._targeted_retry(
                images_base64, 
                missing_fields,
                first_result['data']
            )
            
            return second_result
            
        except Exception as e:
            logger.error(f"Analysis error: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    @staticmethod
    def _first_pass_extraction(images_base64: List[str]) -> Dict[str, Any]:
        """PASS 1: Focused extraction with emphasis on critical fields"""
        
        system_prompt = """Báº¡n lÃ  chuyÃªn gia OCR báº¥t Ä‘á»™ng sáº£n Viá»‡t Nam, chuyÃªn Ä‘á»c chÃ­nh xÃ¡c má»i thÃ´ng tin tá»« áº£nh.

NHIá»†M Vá»¤: QuÃ©t TOÃ€N Bá»˜ áº£nh tá»« trÃªn xuá»‘ng dÆ°á»›i, trÃ¡i sang pháº£i, Ä‘á»c Táº¤T Cáº¢ chá»¯, sá»‘, icon mÃ  KHÃ”NG giáº£ Ä‘á»‹nh cáº¥u trÃºc (khÃ´ng phÃ¢n biá»‡t cá»™t, pháº§n, hay vá»‹ trÃ­). Tá»•ng há»£p thÃ´ng tin tá»« Táº¤T Cáº¢ áº£nh náº¿u cÃ³ nhiá»u.

Ká»¸ NÄ‚NG QUAN TRá»ŒNG:
- Äá»c ká»¹ má»i dÃ²ng chá»¯, icon, vÃ  giÃ¡ trá»‹ Ä‘i kÃ¨m, dÃ¹ á»Ÿ báº¥t ká»³ vá»‹ trÃ­ nÃ o.
- Xá»­ lÃ½ tiáº¿ng Viá»‡t cÃ³ dáº¥u, sá»­a lá»—i Ä‘á»c náº¿u cáº§n (vÃ­ dá»¥: "Coban" cÃ³ thá»ƒ lÃ  "CÆ¡ báº£n").
- Chuyá»ƒn sá»‘ cÃ³ dáº¥u pháº©y thÃ nh dáº¥u cháº¥m: "95,25" â†’ 95.25.
- Náº¿u khÃ´ng tÃ¬m tháº¥y rÃµ rÃ ng â†’ null (khÃ´ng Ä‘oÃ¡n).
- Tráº£ vá» JSON thuáº§n, khÃ´ng markdown."""

        user_prompt = """BÆ¯á»šC 1: QuÃ©t vÃ  liá»‡t kÃª Táº¤T Cáº¢ text/icon visible trong toÃ n bá»™ áº£nh (khÃ´ng bá» sÃ³t báº¥t ká»³ dÃ²ng nÃ o, ká»ƒ cáº£ tiÃªu Ä‘á», mÃ´ táº£, hoáº·c nhÃ£n nhá»). VÃ­ dá»¥ output pháº§n nÃ y: {"all_visible_text": "Danh sÃ¡ch táº¥t cáº£ text: NhÃ  máº·t tiá»n... Diá»‡n tÃ­ch: 95,25 mÂ²... Ná»™i tháº¥t: CÆ¡ báº£n..."}

BÆ¯á»šC 2: Tá»« text quÃ©t Ä‘Æ°á»£c, trÃ­ch xuáº¥t CHÃNH XÃC vÃ  Äáº¦Y Äá»¦ cÃ¡c trÆ°á»ng sau. Æ¯u tiÃªn TUYá»†T Äá»I cÃ¡c trÆ°á»ng quan trá»ng (tÃ¬m ká»¹ á»Ÿ má»i vá»‹ trÃ­, icon, hoáº·c gáº§n nhÃ£n).

âš ï¸ CÃC TRÆ¯á»œNG QUAN TRá»ŒNG NHáº¤T (tuyá»‡t Ä‘á»‘i khÃ´ng bá» sÃ³t, tÃ¬m á»Ÿ báº¥t ká»³ Ä‘Ã¢u):

ğŸ“ DIá»†N TÃCH (usable_area_m2):
- TÃ¬m báº¥t ká»³: "Diá»‡n tÃ­ch", "Diá»‡n tÃ­ch sá»­ dá»¥ng", "DT", "mÂ²", "m2", hoáº·c sá»‘ + "mÂ²" á»Ÿ báº¥t ká»³ vá»‹ trÃ­.
- VD: "Diá»‡n tÃ­ch: 95,25 mÂ²" â†’ 95.25
- VD: "91 mÂ²" â†’ 91
- VD: "95.25 m2" gáº§n icon â–¡ â†’ 95.25
- Náº¿u cÃ³ nhiá»u, láº¥y giÃ¡ trá»‹ chÃ­nh (thÆ°á»ng lÃ  sá»­ dá»¥ng).

ğŸª‘ Ná»˜I THáº¤T (furniture_status):
- TÃ¬m báº¥t ká»³: "Ná»™i tháº¥t", "Ná»™i tháº¥t:", icon ğŸª‘, hoáº·c giÃ¡ trá»‹ nhÆ° "CÆ¡ báº£n", "Äáº§y Ä‘á»§", "Cao cáº¥p" á»Ÿ báº¥t ká»³ vá»‹ trÃ­.
- VD: "Ná»™i tháº¥t: CÆ¡ báº£n" â†’ "CÆ¡ báº£n"
- VD: "Ná»™i tháº¥t: Äáº§y Ä‘á»§" â†’ "Äáº§y Ä‘á»§"
- VD: "Coban" gáº§n nhÃ£n Ná»™i tháº¥t â†’ "CÆ¡ báº£n" (sá»­a náº¿u lá»—i Ä‘á»c)
- Bá» QUA placeholder nhÆ° "VD: Äáº§y Ä‘á»§, CÆ¡ báº£n" hoáº·c "VD:". Chá»‰ láº¥y giÃ¡ trá»‹ thá»±c (sau dáº¥u ":" hoáº·c icon).
- Náº¿u chá»‰ tháº¥y placeholder hoáº·c khÃ´ng rÃµ â†’ null.

CÃC TRÆ¯á»œNG KHÃC (tÃ¬m tÆ°Æ¡ng tá»±, á»Ÿ báº¥t ká»³ vá»‹ trÃ­):
+ property_type: Loáº¡i BDS (nhÃ /cÄƒn há»™/Ä‘áº¥t, vÃ­ dá»¥: "house" náº¿u lÃ  nhÃ  phá»‘).
+ address: Äá»‹a chá»‰ Ä‘áº§y Ä‘á»§ (tá»« mÃ´ táº£ hoáº·c nhÃ£n).
+ bedrooms: Sá»‘ phÃ²ng ngá»§ (tÃ¬m "PhÃ²ng ngá»§", "Sá»‘ phÃ²ng ngá»§", hoáº·c sá»‘ gáº§n icon).
+ bathrooms: Sá»‘ phÃ²ng táº¯m/vá»‡ sinh (tÃ¬m "PhÃ²ng táº¯m", "WC", hoáº·c sá»‘).
+ floors: Sá»‘ táº§ng (tÃ¬m "Sá»‘ táº§ng", "Táº§ng", hoáº·c sá»‘).
+ direction: HÆ°á»›ng nhÃ  (tÃ¬m "HÆ°á»›ng nhÃ ", "HÆ°á»›ng", vÃ­ dá»¥: "TÃ¢y - Báº¯c").
+ balcony_direction: HÆ°á»›ng ban cÃ´ng (náº¿u cÃ³).
+ width_m: Máº·t tiá»n/Chiá»u rá»™ng/Ngang (vÃ­ dá»¥: "4,3 m" â†’ 4.3).
+ length_m: ÄÆ°á»ng vÃ o/Chiá»u dÃ i/SÃ¢u.
+ legal_status: PhÃ¡p lÃ½/Sá»• Ä‘á»/Sá»• há»“ng/Giáº¥y tá».
+ land_area_m2: Diá»‡n tÃ­ch Ä‘áº¥t (náº¿u khÃ¡c usable_area).
+ price_per_m2_vnd: GiÃ¡/mÂ² (náº¿u cÃ³).

Äá»ŠNH Dáº NG OUTPUT (JSON):
{
  "all_visible_text": "TÃ³m táº¯t táº¥t cáº£ text quÃ©t Ä‘Æ°á»£c",
  "property_info": {
    "address": "string hoáº·c null",
    "property_type": "house/apartment/land hoáº·c null",
    "usable_area_m2": sá»‘ hoáº·c null,
    "bedrooms": sá»‘ nguyÃªn hoáº·c null,
    "bathrooms": sá»‘ nguyÃªn hoáº·c null,
    "floors": sá»‘ nguyÃªn hoáº·c null,
    "direction": "string hoáº·c null",
    "balcony_direction": "string hoáº·c null",
    "width_m": sá»‘ hoáº·c null,
    "length_m": sá»‘ hoáº·c null,
    "legal_status": "string hoáº·c null",
    "furniture_status": "string hoáº·c null",
    "land_area_m2": sá»‘ hoáº·c null,
    "price_per_m2_vnd": sá»‘ hoáº·c null
  },
  "condition_assessment": {
    "overall_condition": "string hoáº·c null",
    "cleanliness": "string hoáº·c null",
    "maintenance_status": "string hoáº·c null",
    "major_issues": [],
    "overall_description": "string hoáº·c null"
  }
}

âš ï¸ QUÃ‰T Ká»¸ TOÃ€N Bá»˜! KhÃ´ng bá» sÃ³t diá»‡n tÃ­ch vÃ  ná»™i tháº¥t dÃ¹ á»Ÿ vá»‹ trÃ­ nÃ o."""

        try:
            # Build content with all images
            content = [{"type": "text", "text": user_prompt}]
            for img_b64 in images_base64:
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_b64}",
                        "detail": "high"
                    }
                })
            
            # Call GPT-4V
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": content}
                ],
                max_tokens=3000,
                temperature=0
            )
            
            # Parse response
            response_text = response.choices[0].message.content.strip()
            raw_text = response.choices[0].message.content.strip()
            print("\n" + "="*60)
            print("RAW RESPONSE Tá»ª GPT (PASS 1)")
            print("="*60)
            print(raw_text)
            print("="*60 + "\n")
            # Clean markdown
            if response_text.startswith("```json"):
                response_text = response_text.replace("```json", "").replace("```", "").strip()
            elif response_text.startswith("```"):
                response_text = response_text.replace("```", "").strip()
            
            # Parse JSON
            try:
                result = json.loads(response_text)
            except json.JSONDecodeError:
                json_match = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_match >= 0 and json_end > json_match:
                    result = json.loads(response_text[json_match:json_end])
                else:
                    raise ValueError(f"Invalid JSON: {response_text[:300]}")
            
            logger.info(f"âœ… PASS 1 completed. Tokens: {response.usage.prompt_tokens}/{response.usage.completion_tokens}")
            
            return {
                "success": True,
                "data": result,
                "raw_response": response_text,
                "usage": {
                    "input_tokens": response.usage.prompt_tokens,
                    "output_tokens": response.usage.completion_tokens
                }
            }
            
        except Exception as e:
            logger.error(f"PASS 1 error: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            }

    @staticmethod
    def _validate_critical_fields(data: Dict[str, Any]) -> List[str]:
        """Check for missing critical fields"""
        missing = []
        property_info = data.get("property_info", {})
        
        field_mapping = {
            "usable_area_m2": "Diá»‡n tÃ­ch sá»­ dá»¥ng",
            "bedrooms": "Sá»‘ phÃ²ng ngá»§",
            "bathrooms": "Sá»‘ phÃ²ng táº¯m",
            "floors": "Sá»‘ táº§ng",
            "direction": "HÆ°á»›ng nhÃ ",
            "legal_status": "PhÃ¡p lÃ½",
            "furniture_status": "Ná»™i tháº¥t",
            "width_m": "Máº·t tiá»n",
            "length_m": "ÄÆ°á»ng vÃ o"
        }
        
        for field, display_name in field_mapping.items():
            value = property_info.get(field)
            if value is None or value == "" or value == 0:
                missing.append(field)
                logger.debug(f"âŒ Missing: {display_name} ({field})")
        
        return missing
    
    @staticmethod
    def _targeted_retry(
        images_base64: List[str], 
        missing_fields: List[str],
        previous_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """PASS 2: Laser-focused retry for critical missed fields"""
        print(f"\nPASS 2: Äang tÃ¬m láº¡i {missing_fields} vÃ¬ GPT bá» sÃ³t!")
        # Enhanced field labels with more search hints
        field_labels = {
            "usable_area_m2": "Diá»‡n tÃ­ch / Diá»‡n tÃ­ch sá»­ dá»¥ng / DT / báº¥t ká»³ sá»‘ + mÂ² / m2 á»Ÿ má»i vá»‹ trÃ­",
            "bedrooms": "Sá»‘ phÃ²ng ngá»§ / PhÃ²ng ngá»§ / sá»‘ gáº§n icon phÃ²ng",
            "bathrooms": "Sá»‘ phÃ²ng táº¯m / PhÃ²ng táº¯m, vá»‡ sinh / WC / sá»‘",
            "floors": "Sá»‘ táº§ng / Táº§ng / sá»‘",
            "direction": "HÆ°á»›ng nhÃ  / HÆ°á»›ng / HÆ°á»›ng chÃ­nh / TÃ¢y - Báº¯c v.v.",
            "legal_status": "PhÃ¡p lÃ½ / Giáº¥y tá» / Sá»• Ä‘á» / Sá»• há»“ng / Sá»•",
            "furniture_status": "Ná»™i tháº¥t / TÃ¬nh tráº¡ng ná»™i tháº¥t / icon ğŸª‘ / CÆ¡ báº£n / Äáº§y Ä‘á»§ (sá»­a lá»—i nhÆ° Coban â†’ CÆ¡ báº£n)",
            "width_m": "Máº·t tiá»n / Chiá»u rá»™ng / Ngang / sá»‘ + m",
            "length_m": "ÄÆ°á»ng vÃ o / Chiá»u dÃ i / SÃ¢u / sá»‘ + m"
        }
        
        missing_labels = [field_labels.get(f, f) for f in missing_fields]
        
        # Ultra-focused retry prompt
        retry_prompt = f"""âš ï¸ QUÃ‰T Láº I TOÃ€N Bá»˜ áº¢NH Äá»‚ TÃŒM CÃC TRÆ¯á»œNG Bá»Š Bá» SÃ“T:

{chr(10).join(f'{i+1}. {label}' for i, label in enumerate(missing_labels))}

HÆ¯á»šNG DáºªN:
- QuÃ©t Tá»ª TRÃŠN XUá»NG DÆ¯á»šI, TRÃI SANG PHáº¢I, Ä‘á»c Má»ŒI CHá»®/Sá»/ICON.
- TÃ¬m á»Ÿ Báº¤T Ká»² Vá»Š TRÃ, khÃ´ng giáº£ Ä‘á»‹nh cáº¥u trÃºc.
- Äáº·c biá»‡t chÃº Ã½:
  * Sá»‘ + "mÂ²" hoáº·c gáº§n "Diá»‡n tÃ­ch" â†’ usable_area_m2
  * "Ná»™i tháº¥t" + giÃ¡ trá»‹ (CÆ¡ báº£n/Äáº§y Ä‘á»§) hoáº·c icon â†’ furniture_status
  * Sá»­a lá»—i Ä‘á»c náº¿u cáº§n (Coban â†’ CÆ¡ báº£n)

VÃ Dá»¤:
âœ… "95,25 mÂ²" â†’ usable_area_m2: 95.25
âœ… "Ná»™i tháº¥t: CÆ¡ báº£n" â†’ furniture_status: "CÆ¡ báº£n"
âœ… "Coban" â†’ furniture_status: "CÆ¡ báº£n"

OUTPUT (chá»‰ cÃ¡c trÆ°á»ng tÃ¬m Ä‘Æ°á»£c):
{{
  {', '.join(f'"{f}": value' for f in missing_fields)}
}}

âš ï¸ TÃŒM Ká»¸! ThÃ´ng tin cháº¯c cháº¯n cÃ³ trong áº£nh!"""

        try:
            content = [{"type": "text", "text": retry_prompt}]
            for img_b64 in images_base64:
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_b64}",
                        "detail": "high"
                    }
                })
            
            logger.info(f"ğŸ¯ PASS 2: Laser-targeting {len(missing_fields)} fields")
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": "Báº¡n lÃ  chuyÃªn gia OCR. QUÃ‰T TOÃ€N Bá»˜ áº£nh vÃ  tÃ¬m CHÃNH XÃC cÃ¡c trÆ°á»ng bá»‹ thiáº¿u. KhÃ´ng Ä‘Æ°á»£c bá» sÃ³t!"
                    },
                    {"role": "user", "content": content}
                ],
                max_tokens=1000,
                temperature=0
            )
            
            retry_text = response.choices[0].message.content.strip()
            
            # Clean and parse
            if retry_text.startswith("```"):
                retry_text = retry_text.replace("```json", "").replace("```", "").strip()
            
            retry_result = json.loads(retry_text)
            
            # Merge with previous data
            property_info = previous_data.get("property_info", {})
            recovered_fields = []
            for field, value in retry_result.items():
                if value is not None and value != "":
                    property_info[field] = value
                    recovered_fields.append(field)
                    logger.info(f"âœ… Recovered: {field} = {value}")
            
            previous_data["property_info"] = property_info
            
            logger.info(f"âœ… PASS 2 completed. Tokens: {response.usage.prompt_tokens}/{response.usage.completion_tokens}")
            logger.info(f"ğŸ“Š Recovery rate: {len(recovered_fields)}/{len(missing_fields)} fields")
            
            return {
                "success": True,
                "data": previous_data,
                "usage": {
                    "input_tokens": response.usage.prompt_tokens,
                    "output_tokens": response.usage.completion_tokens
                },
                "retry_info": {
                    "attempted_fields": missing_fields,
                    "recovered_fields": recovered_fields,
                    "recovery_rate": f"{len(recovered_fields)}/{len(missing_fields)}"
                }
            }
            
        except Exception as e:
            logger.error(f"PASS 2 error: {str(e)}")
            # Return original data if retry fails
            return {
                "success": True,
                "data": previous_data,
                "warning": f"Retry failed: {str(e)}"
            }
    
    @staticmethod
    def extract_property_info(ai_result: Dict[str, Any]) -> Dict[str, Any]:
        try:
            return ai_result.get("data", {}).get("property_info", {})
        except:
            return {}
    
    @staticmethod
    def extract_condition_assessment(ai_result: Dict[str, Any]) -> Dict[str, Any]:
        try:
            return ai_result.get("data", {}).get("condition_assessment", {})
        except:
            return {}


# Export functions
def analyze_images_to_property_form(images_base64: List[str]) -> Dict[str, Any]:
    return ImageToFormAnalyzer.analyze_images_to_form(images_base64)

def get_property_info_from_analysis(ai_result: Dict[str, Any]) -> Dict[str, Any]:
    return ImageToFormAnalyzer.extract_property_info(ai_result)

def get_condition_assessment_from_analysis(ai_result: Dict[str, Any]) -> Dict[str, Any]:
    return ImageToFormAnalyzer.extract_condition_assessment(ai_result)